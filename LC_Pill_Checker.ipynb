{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOE4VAYUQuYpAyibQ3IYxps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pauullamm/LC_Pill_Checker/blob/main/LC_Pill_Checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LC_Pill_Checker: Experimenting with retrieval augmented generation (RAG) with the LangChain framework to identify tablets/capsules by their text description\n",
        "\n",
        "## General Impressions:\n",
        "\n",
        "1. Data issues: text descriptions are not ideal - carries too much ambiguity for language model to differentiate pills e.g. \"white, biconvex, round, debosed with \"\" on one side\" carries a lot of similarities with other pill descriptions.\n",
        "\n",
        "2. Formatting of documents is crucial to reduce noise of data.\n",
        "\n",
        "3. Different types of embeddings models/vector stores still need to be experimented with to see if there is any improvement in performance.\n",
        "\n",
        "4. Might need to explore dimensionality reduction (UMAP) for 'curse of dimensionality'\n",
        "\n",
        "### DISCLAIMER: The information below is provided for private study and / or personal use purposes only, and is not intended to be a substitute for a health care provider’s consultation or advice. The information below does not constitute legal or technical advice."
      ],
      "metadata": {
        "id": "vJOMvLjo9uYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YNcfe7k185tS"
      },
      "outputs": [],
      "source": [
        "#@title DEPENDENCIES\n",
        "\n",
        "!pip install --upgrade openai -q\n",
        "!pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken\n",
        "!pip install beautifulsoup4 -q\n",
        "!pip install chromadb -q\n",
        "!pip install aiofiles -q\n",
        "!pip install lancedb -q\n",
        "!pip install umap-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title IMPORTS\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "import umap\n",
        "import aiofiles\n",
        "import string\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.vectorstores import SKLearnVectorStore\n",
        "from langchain.vectorstores import LanceDB\n",
        "\n",
        "\n",
        "\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eaTTpbsr9BjO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use:\n",
        "\n",
        "1. Obtain api key from \"https://openai.com/blog/openai-api\"\n",
        "2. Prepare tablet/capsules text description data in a .txt file in the following format: <br> Drug name | Drug description | Manufacturer \\n (the custom document loader splits the text into smaller documents by each newline)\n",
        "3. Describe a tablet/capsule under question_to_ask"
      ],
      "metadata": {
        "id": "7dnVP_0-BJfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"\" # @param {type:\"string\"}\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "urWu6qi89Bg-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CustomDocumentLoader class from LangChain\n",
        "from typing import AsyncIterator, Iterator\n",
        "\n",
        "from langchain_core.document_loaders import BaseLoader\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "class CustomDocumentLoader(BaseLoader):\n",
        "    \"\"\"An example document loader that reads a file line by line.\"\"\"\n",
        "\n",
        "    def __init__(self, file_path: str) -> None:\n",
        "        \"\"\"Initialize the loader with a file path.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to load.\n",
        "        \"\"\"\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def lazy_load(self) -> Iterator[Document]:  # <-- Does not take any arguments\n",
        "        \"\"\"A lazy loader that reads a file line by line.\n",
        "\n",
        "        When you're implementing lazy load methods, you should use a generator\n",
        "        to yield documents one by one.\n",
        "        \"\"\"\n",
        "        with open(self.file_path, encoding=\"utf-8\") as f:\n",
        "            line_number = 0\n",
        "            for line in f:\n",
        "                yield Document(\n",
        "                    page_content=line,\n",
        "                    metadata={\"line_number\": line_number, \"source\": self.file_path},\n",
        "                )\n",
        "                line_number += 1\n",
        "\n",
        "    # alazy_load is OPTIONAL.\n",
        "    # If you leave out the implementation, a default implementation which delegates to lazy_load will be used!\n",
        "    async def alazy_load(\n",
        "        self,\n",
        "    ) -> AsyncIterator[Document]:  # <-- Does not take any arguments\n",
        "        \"\"\"An async lazy loader that reads a file line by line.\"\"\"\n",
        "        # Requires aiofiles\n",
        "        # Install with `pip install aiofiles`\n",
        "        # https://github.com/Tinche/aiofiles\n",
        "\n",
        "        async with aiofiles.open(self.file_path, encoding=\"utf-8\") as f:\n",
        "            line_number = 0\n",
        "            async for line in f:\n",
        "                yield Document(\n",
        "                    page_content=line,\n",
        "                    metadata={\"line_number\": line_number, \"source\": self.file_path},\n",
        "                )\n",
        "                line_number += 1\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7vGT0cw_9Bem"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load pill description data (.txt file) with document loader\n",
        "path_to_file = \"\" # @param {type:\"string\"}\n",
        "loader = CustomDocumentLoader(path_to_file)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHsdYHpcAnqg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Splitting text to documents - splitting might not be necessary if document size is small? (skip)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z7heWMfQ9Bce"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text embeddings with openai and storing in vector store (currently using LanceDB)\n",
        "embeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "vector_store = LanceDB.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings_model\n",
        ")\n"
      ],
      "metadata": {
        "id": "YJ0_6f2J9BaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example question: '''I have tablets that are Orange, modified capsule shaped, biconvex film-coated tablet (approximately 20.6 x 8.6 mm), debossed with “ H” on one side and “ A1” on the other side.. What is this drug and its manufacturer? - Abacavir/Lamivudine 600 mg/300 mg film-coated tablets | Amarox Limited\n",
        "'''"
      ],
      "metadata": {
        "id": "8qf_IQC29U66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_to_ask = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6aT0I9yV9bmu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter\n",
        "\n",
        "_filter = LLMChainFilter.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=_filter, base_retriever=retriever\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(\n",
        "    question_to_ask\n",
        ")"
      ],
      "metadata": {
        "id": "_rwotAeV9dh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(\n",
        "        f\"\\n{'-' * 100}\\n\".join(\n",
        "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
        "        )\n",
        "    )\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UtldLu99dfb",
        "outputId": "a0f307af-6fda-4dbd-a4c8-92534d6236e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based on the provided context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {input}\"\"\")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "retriever = vector_store.as_retriever()\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "retrieval_chain = (\n",
        "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ],
      "metadata": {
        "id": "ecQGltop9ddF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE9BbLxIi2n7"
      },
      "outputs": [],
      "source": [
        "retrieval_chain.invoke(question_to_ask)"
      ]
    }
  ]
}